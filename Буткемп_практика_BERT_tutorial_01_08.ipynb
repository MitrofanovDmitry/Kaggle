{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "–ë—É—Ç–∫–µ–º–ø_–ø—Ä–∞–∫—Ç–∏–∫–∞_BERT_tutorial_01_08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6222c9cac434deb89d8efda832e39fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e1de17d6c884f40bab8d8fdb1bce7c6",
              "IPY_MODEL_58f45083fe0847a4bd6c7e6c684d9af0",
              "IPY_MODEL_b05636d383ed4b1bb8000824113aff22"
            ],
            "layout": "IPY_MODEL_b2b4bff4c7e74dbb87f0213a3688362b"
          }
        },
        "1e1de17d6c884f40bab8d8fdb1bce7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed43a18dd0c74de2b97202e2bf60e149",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_136e8a953ae84265bd9772beca57c734",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "58f45083fe0847a4bd6c7e6c684d9af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01393675009a43648fbbfe55e8ece7ec",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7b4c46785e049b0a199e3d79afcd0e8",
            "value": 440473133
          }
        },
        "b05636d383ed4b1bb8000824113aff22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9493efa54614d3abfe260fa47c3f584",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ba677ae701f444f7bbfa44026091940c",
            "value": " 420M/420M [00:07&lt;00:00, 58.3MB/s]"
          }
        },
        "b2b4bff4c7e74dbb87f0213a3688362b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed43a18dd0c74de2b97202e2bf60e149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "136e8a953ae84265bd9772beca57c734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01393675009a43648fbbfe55e8ece7ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b4c46785e049b0a199e3d79afcd0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9493efa54614d3abfe260fa47c3f584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba677ae701f444f7bbfa44026091940c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MitrofanovDmitry/Kaggle/blob/main/%D0%91%D1%83%D1%82%D0%BA%D0%B5%D0%BC%D0%BF_%D0%BF%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0_BERT_tutorial_01_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Fine-Tuning with PyTorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJR6t_gCQe_x"
      },
      "source": [
        "–°–µ–≥–æ–¥–Ω—è –º—ã —Ä–∞–∑–±–µ—Ä–µ–º –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å BERT –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ huggingface PyTorch –∏ –Ω–∞—É—á–∏–º—Å—è –µ–≥–æ —Ñ–∞–π–Ω—Ç—å—é–Ω–∏—Ç—å –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. \n",
        "\n",
        "\n",
        "–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç (by Chris McCormick and Nick Ryan) –º–æ–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å [–∑–¥–µ—Å—å](http://mccormickml.com/2019/07/22/BERT-fine-tuning/), –∞ Colab Notebook  –Ω–∞–π—Ç–∏ [–∑–¥–µ—Å—å](https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX). \n",
        "\n",
        "\n",
        "\n",
        "–í–∏–¥–µ–æ-—Ä–∞–∑–±–æ—Ä –Ω–∞ Youtube: \n",
        "\n",
        "* [–ß–∞—Å—Ç—å 1](https://youtu.be/x66kkDnbzi4) \n",
        "\n",
        "* [–ß–∞—Å—Ç—å 2](https://youtu.be/Hnvb9b7a_Ps).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCgvR9INuP5q"
      },
      "source": [
        "\n",
        "## What is BERT?\n",
        "\n",
        "\n",
        "BERT ‚Äî —ç—Ç–æ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –æ—Ç Google, –ø–æ–∫–∞–∑–∞–≤—à–∞—è –æ—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ü–µ–ª–æ–º —Ä—è–¥–µ –∑–∞–¥–∞—á. –° –ø–æ–º–æ—â—å—é BERT –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º—ã —Å –ò–ò –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞: –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –∑–∞–¥–∞–Ω–Ω—ã–µ –≤ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ, —Å–æ–∑–¥–∞–≤–∞—Ç—å —á–∞—Ç-–±–æ—Ç–æ–≤, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∏, –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaVGdtOkuXUZ"
      },
      "source": [
        "\n",
        "## –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ Fine-Tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5llwu8GBuqMb"
      },
      "source": [
        "–ï—Å–ª–∏ –ø—Ä–µ–¥–æ–±—É—á–∏—Ç—å BERT –Ω–∞ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–∞—Ö —Ç–µ–∫—Å—Ç–∞, —Ç–æ –æ–Ω –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ –∏ —Å –±–æ–ª—å—à–∏–º –æ—Ç—Ä—ã–≤–æ–º –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ —Å–∞–º—ã—Ö —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞. –ü–æ —Å—É—Ç–∏, —Ç–∞–∫–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –Ω–∞ –≤—ã—Ö–æ–¥–µ —Å–æ–∑–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è —Å–ª–æ–≤, –∏ –¥–∞–∂–µ —Ü–µ–ª—ã—Ö —Ñ—Ä–∞–∑. –ê –Ω–∞–≤–µ—Å–∏–≤ —Å–≤–µ—Ä—Ö—É –Ω–∞–¥ —Ç–∞–∫–æ–π —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª—å—é –Ω–µ–±–æ–ª—å—à–æ–π –±–ª–æ–∫ –∏–∑ –ø–∞—Ä—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–µ–≤ –Ω–µ–π—Ä–æ–Ω–æ–≤, –º–æ–∂–Ω–æ –¥–æ–æ–±—É—á–∏—Ç—å —ç—Ç—É –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –Ω–∞ –ª—é–±—ã–µ –∑–∞–¥–∞—á–∏.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "## 1.1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI0iOY8zvZzL"
      },
      "source": [
        "\n",
        "Google Colab –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ GPU –∏ TPU! –¢–∞–∫ –∫–∞–∫ –º—ã –±—É–¥–µ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, GPU –Ω–∞–º –æ—á–µ–Ω—å –ø—Ä–∏–≥–æ–¥—è—Ç—Å—è! \n",
        "\n",
        "`Edit ü°í Notebook Settings ü°í Hardware accelerator ü°í (GPU)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "–î–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ `torch` —Å–º–æ–≥–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å —ç—Ç–æ—Ç GPU –∫–∞–∫ `device`. –î–∞–ª–µ–µ, –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –º—ã –æ—Ç–ø—Ä–∞–≤–∏–º –º–æ–¥–µ–ª–∏ –∏ –¥–∞–Ω–Ω—ã–µ –Ω–∞ —ç—Ç–æ—Ç `device`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "e95a8460-fef6-474f-d92c-e23dd848c95c"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "## 1.2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Hugging Face "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_N2UDLevYWn"
      },
      "source": [
        "\n",
        "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–∞–∫–µ—Ç [transformers](https://github.com/huggingface/transformers) –∏–∑ Hugging Face, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–¥–æ–±–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å BERT'–æ–º –∏ –º–Ω–æ–≥–∏–º–∏ –¥—Ä—É–≥–∏–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏. \n",
        "\n",
        "–í –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Hugging Face –æ–¥–Ω–∞ –∏–∑ —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö pytorch –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏. –ü–æ–º–∏–º–æ —Å–∞–º–∏—Ö –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ —Ç–∞–∫–∂–µ –≤–∫–ª—é—á–∞–µ—Ç —É–¥–æ–±–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ñ–∞–π–Ω—Ç—å—é–Ω–∏–Ω–≥–∞ –∏ —Ä–∞–±–æ—Ç—ã —Å —ç—Ç–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è –º–Ω–æ–≥–∏—Ö –∑–∞–¥–∞—á. –ù–∞–ø—Ä–∏–º–µ—Ä, —Å–µ–≥–æ–¥–Ω—è –º—ã –±—É–¥–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é `BertForSequenceClassification`.\n",
        "\n",
        "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ —Ç–∞–∫–∂–µ –≤–∫–ª—é—á–∞–µ—Ç –∫–ª–∞—Å—Å—ã –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤, Question-Answering, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –¥—Ä—É–≥–∏–µ. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —ç—Ç–∏—Ö –∫–ª–∞—Å—Å–æ–≤ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ø—Ä–æ—â–∞–µ—Ç —Ä–∞–±–æ—Ç—É —Å –º–æ–¥–µ–ª—å—é.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NmMdkZO8R6q",
        "outputId": "d8936213-0d9e-424c-e36f-d4e6c39fb8c3"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.7 MB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.6 MB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 596 kB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxddqmruamSj"
      },
      "source": [
        "–ö–æ–¥ –≤ —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø—Ä–∏–º–µ—Ä–∞ [run_glue.py](https://github.com/huggingface/transformers/blob/master/examples/run_glue.py) –∏–∑ huggingface.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "# 2. –ó–∞–≥—Ä—É–∂–∞–µ–º CoLA Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ZKxKc04Btk"
      },
      "source": [
        "–ú—ã –±—É–¥–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å [The Corpus of Linguistic Acceptability (CoLA)](https://nyu-mll.github.io/CoLA/) - –¥–∞—Ç–∞—Å–µ—Ç–æ–º –¥–ª—è –∑–∞–¥–∞—á–∏ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –û–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞–±–æ—Ä –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –Ω–∞ 2 –∫–ª–∞—Å—Å–∞: *–≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ* –∏ *–≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn"
      },
      "source": [
        "## 2.1. –ó–∞–≥—Ä—É–∑–∫–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZNVW6xd0T0X"
      },
      "source": [
        "–í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –ø–∞–∫–µ—Ç–æ–º `wget` –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m6AnuFv0QXQ",
        "outputId": "39f0b480-1193-4313-a217-07ae96593373"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=4e4e2c5079690475a8ce4ef73c1fc1ae2aa521096fe3eabb46b1cc20b5793005\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08pO03Ff1BjI"
      },
      "source": [
        "–î–∞—Ç–∞—Å–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏: https://nyu-mll.github.io/CoLA/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMtmPMkBzrvs",
        "outputId": "a438353d-2d95-4f01-881a-8aa382aebff7"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mKctx-ll2FB"
      },
      "source": [
        "–†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv-tNv20dnH"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "## 2.2. –ü–∞—Ä—Å–∏–Ω–≥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYWzeGSY2xh3"
      },
      "source": [
        "–ó–∞–≥—Ä—É–∑–∏–º –¥–∞—Ç–∞—Å–µ—Ç –≤ DataFrame. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "_UkeC7SG2krJ",
        "outputId": "6eb18d2c-78c9-4cc1-fd3d-f80784f9c5bb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentence_source  label label_notes  \\\n",
              "2006           rhl07      1         NaN   \n",
              "3396            l-93      1         NaN   \n",
              "4102            ks08      0           *   \n",
              "1123            r-67      0           *   \n",
              "5931            c_13      1         NaN   \n",
              "380             bc01      1         NaN   \n",
              "1039            bc01      1         NaN   \n",
              "1028            bc01      1         NaN   \n",
              "6294            c_13      1         NaN   \n",
              "1774            r-67      1         NaN   \n",
              "\n",
              "                                               sentence  \n",
              "2006               Fred threw the ball under the porch.  \n",
              "3396                   He waltzed her across the floor.  \n",
              "4102       You should avoid to travel in the rush hour.  \n",
              "1123  I consider to be a fool the senator who made t...  \n",
              "5931                                John bit the apple.  \n",
              "380   No candidate can predict how many people will ...  \n",
              "1039  Exactly half of the students attended some sem...  \n",
              "1028  Most guests will be offended if we don't invit...  \n",
              "6294  To be able to buy myself a ticket to France wo...  \n",
              "1774  The raise which Scrooge generously gave Tom's ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fd4d3d6-1985-46a1-9287-fdc7cc8249af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006</th>\n",
              "      <td>rhl07</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fred threw the ball under the porch.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3396</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>He waltzed her across the floor.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4102</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>You should avoid to travel in the rush hour.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1123</th>\n",
              "      <td>r-67</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>I consider to be a fool the senator who made t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5931</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John bit the apple.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No candidate can predict how many people will ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Exactly half of the students attended some sem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1028</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Most guests will be offended if we don't invit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6294</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To be able to buy myself a ticket to France wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1774</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The raise which Scrooge generously gave Tom's ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fd4d3d6-1985-46a1-9287-fdc7cc8249af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7fd4d3d6-1985-46a1-9287-fdc7cc8249af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7fd4d3d6-1985-46a1-9287-fdc7cc8249af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWzpPi92UAH"
      },
      "source": [
        "–ù–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è —Ç–æ–ª—å–∫–æ 2 –∫–æ–ª–æ–Ω–∫–∏ `sentence` –∏ `label`, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ \"acceptibility judgment\" (0=unacceptable, 1=acceptable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_LpQfzCn9_o"
      },
      "source": [
        "–î–∞–≤–∞–π—Ç–µ –≤–∑–≥–ª—è–Ω–µ–º –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "blqIvQaQncdJ",
        "outputId": "93911193-d48a-4604-b023-f9e3683e33fc"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "1961                      Bill and Mary washed himself.      0\n",
              "4723                     A mile to work was run by him.      0\n",
              "1368  We elected employer president the boy's guardi...      0\n",
              "7986        Medea wondered if that the potion was ready      0\n",
              "4075               How much money Gordon spent is true.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5380319f-60a4-4c4b-94c1-908cef8ef794\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1961</th>\n",
              "      <td>Bill and Mary washed himself.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4723</th>\n",
              "      <td>A mile to work was run by him.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1368</th>\n",
              "      <td>We elected employer president the boy's guardi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7986</th>\n",
              "      <td>Medea wondered if that the potion was ready</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4075</th>\n",
              "      <td>How much money Gordon spent is true.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5380319f-60a4-4c4b-94c1-908cef8ef794')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5380319f-60a4-4c4b-94c1-908cef8ef794 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5380319f-60a4-4c4b-94c1-908cef8ef794');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è & –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Input \n",
        "\n",
        "–í –¥–∞–Ω–Ω–æ–π —Å–µ–∫—Ü–∏–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∫ —Ñ–æ—Ä–º–∞—Ç—É, —Å –∫–æ—Ç–æ—Ä—ã–º —Ä–∞–±–æ—Ç–∞–µ—Ç BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5"
      },
      "source": [
        "## 3.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2"
      },
      "source": [
        "–ß—Ç–æ–±—ã –ø–æ–¥–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ —Ç–µ–∫—Å—Ç –≤ BERT'–∞, –µ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞–∑–±–∏—Ç—å –Ω–∞ —Ç–æ–∫–µ–Ω—ã, –∞ –∑–∞—Ç–µ–º –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–∫–µ–Ω—ã –∏—Ö –ø–æ—Ä—è–¥–∫–æ–≤—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏ –≤ —Å–ª–æ–≤–∞—Ä–µ.\n",
        "\n",
        "–¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å –ø–æ–º–æ—â—å—é —Ä–æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –º–æ–¥–µ–ª–∏, –∏–Ω–∞—á–µ –º–æ–∂–µ—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –ø—É—Ç–∞–Ω–∏—Ü–∞ —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z474sSC6oe7A",
        "outputId": "1e547dd5-41db-4afc-f26e-7da19a33f7f9"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzmtleW6KmJ"
      },
      "source": [
        "–ü—Ä–∏–º–µ–Ω–∏–º —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∫ –æ–¥–Ω–æ–º—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ –ø–æ–ª—É—á–∏—Ç—Å—è.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLIbudgfh6F0",
        "outputId": "e5e5ac4b-7d42-449d-c72b-bb06682d4ebe"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeNIc4auFUdF"
      },
      "source": [
        "–≠—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤ –æ–¥–Ω–æ –¥–µ–π—Å—Ç–≤–∏–µ —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `tokenize.encode`, –Ω–æ –ø—Ä–µ–∂–¥–µ –¥–∞–≤–∞–π—Ç–µ –æ–±—Å—É–¥–∏–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—é."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viKGCCh8izww"
      },
      "source": [
        "## 3.2. Required Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDcqNlvVhL5W"
      },
      "source": [
        "\n",
        "1. –î–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. \n",
        "2. –î–æ–ø–æ–ª–Ω–∏—Ç—å & —É—Å–µ—á—å –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ –æ–¥–Ω–æ–π –¥–ª–∏–Ω—ã.\n",
        "3. –í —è–≤–Ω–æ–º –≤–∏–¥–µ –æ—Ç–¥–µ–ª–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –æ—Ç padding-—Ç–æ–∫–µ–Ω–æ–≤ —Å –ø–æ–º–æ—â—å—é \"attention mask\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6mceWWOjZnw"
      },
      "source": [
        "### –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykk0P9JiKtVe"
      },
      "source": [
        "\n",
        "**`[SEP]`**\n",
        "\n",
        "–í –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω `[SEP]`. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86C9objaKu8f"
      },
      "source": [
        "**`[CLS]`**\n",
        "\n",
        "–î–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ –Ω–∞—á–∞–ª–µ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–±–∞–≤–∏—Ç—å —Ç–æ–∫–µ–Ω `[CLS]`.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u51v0kFxeteu"
      },
      "source": [
        "### Sentence Length & Attention Mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPNuwqZVK3T6"
      },
      "source": [
        "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–º–µ—é—Ç —Ä–∞–∑–Ω—É—é –¥–ª–∏–Ω—É. –ö–∞–∫ –∂–µ BERT —Ä–µ—à–∞–µ—Ç —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É? \n",
        "\n",
        "–£ BERT'–∞ –µ—Å—Ç—å 2 –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –≤—Ö–æ–¥–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è:\n",
        "1. –í—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—É—é —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –¥–ª–∏–Ω—É.\n",
        "2. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ø—É—Å—Ç–∏–º–∞—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π 512 —Ç–æ–∫–µ–Ω–æ–≤.\n",
        "\n",
        "–î–ª—è –ø–∞–¥–¥–∏–Ω–≥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω `[PAD]` —Å –∏–Ω–¥–µ–∫—Å–æ–º 0 –≤ —Å–ª–æ–≤–∞—Ä–µ BERT'–∞. \n",
        "\n",
        "<img src=\"http://www.mccormickml.com/assets/BERT/padding_and_mask.png\" width=\"600\">\n",
        "\n",
        "\"Attention Mask\" —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–æ–∫ –∏–∑ 0 –∏ 1, —É–∫–∞–∑—ã–≤–∞—é—â–∏—Ö, –∫–∞–∫–∏–µ —Ç–æ–∫–µ–Ω—ã —è–≤–ª—è—é—Ç—Å—è PAD-—Ç–æ–∫–µ–Ω–∞–º–∏, –∞ –∫–∞–∫–∏–µ –Ω–µ—Ç. –≠—Ç–∞ –º–∞—Å–∫–∞ –ø–æ–º–æ–≥–∞–µ—Ç BERT'—É  –Ω–µ —É—á–∏—Ç—ã–≤–∞—Ç—å PAD-—Ç–æ–∫–µ–Ω—ã –ø—Ä–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n",
        "\n",
        "–¢–∞–∫–∂–µ —Å—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤–ª–∏—è–µ—Ç –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è. \n",
        "–ü—Ä–∏–º–µ—Ä –¥–ª—è Tesla K80:\n",
        "\n",
        "`MAX_LEN = 128  -->  Training epochs take ~5:28 each`\n",
        "\n",
        "`MAX_LEN = 64   -->  Training epochs take ~2:57 each`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ"
      },
      "source": [
        "## 3.3. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U28qy4P-NwQ9"
      },
      "source": [
        "–í –±–∏–±–ª–∏–æ—Ç–µ–∫–µ transformers –µ—Å—Ç—å –ø–æ–ª–µ–∑–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è `encode`, —Å –ø–æ–º–æ—â—å—é –∫–æ—Ç–æ—Ä–æ–π —É–¥–æ–±–Ω–æ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n",
        "\n",
        "–ù–æ –ø–µ—Ä–µ–¥ —Ç–µ–º, –∫–∞–∫ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, –¥–∞–≤–∞–π—Ç–µ –Ω–∞–π–¥–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\n",
        "\n",
        "\n",
        "–í —è—á–µ–π–∫–µ –Ω–∏–∂–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø—Ä–æ—Ö–æ–¥ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKsH2sU0OCQA",
        "outputId": "2dee98ba-7cc8-499b-be10-5b3515aeb834"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M296yz577fV"
      },
      "source": [
        "–£—Å–µ—á–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ —ç—Ç–æ–π –¥–ª–∏–Ω—ã."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIWAoWL2RK1p"
      },
      "source": [
        "–í—Å–µ –≥–æ—Ç–æ–≤–æ –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏.\n",
        "\n",
        "–í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è —Ñ—É–Ω–∫—Ü–∏–µ–π `tokenizer.encode_plus`, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–ø–æ–ª–Ω–∏—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —à–∞–≥–∏\n",
        "\n",
        "1. –†–∞–∑–æ–±—å–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ —Ç–æ–∫–µ–Ω—ã.\n",
        "2. –î–æ–±–∞–≤–∏—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã `[CLS]` –∏ `[SEP]`.\n",
        "3. –ó–∞–º–µ–Ω–∏—Ç —Ç–æ–∫–µ–Ω—ã –Ω–∞ –∏—Ö ID.\n",
        "4. –ü—Ä–∏–≤–µ–¥–µ—Ç –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫ –æ–¥–Ω–æ–π –¥–ª–∏–Ω–µ - max_len.\n",
        "5. –°–æ–∑–¥–∞—Å—Ç attention masks.\n",
        "\n",
        "–ü–µ—Ä–≤—ã–µ —á–µ—Ç—ã—Ä–µ —Å–≤–æ–π—Å—Ç–≤–∞ —Ç–∞–∫–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –≤ —Ñ—É–Ω–∫—Ü–∏–∏ `tokenizer.encode`, –Ω–æ –º—ã –≤–æ—Å–ø–æ–ª—å–∑–µ–º—Å—è `tokenizer.encode_plus`, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å attention masks (5–æ–µ —Å–≤–æ–π—Å—Ç–≤–æ. –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ [–∑–¥–µ—Å—å](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus)).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bBdb3pt8LuQ",
        "outputId": "37dfa2fd-117a-4d68-fd05-63e97efb633d"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "## 3.4. Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06"
      },
      "source": [
        "–†–∞–∑–¥–µ–ª–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ train –∏ val –≤ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏  90% –∫ 10%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEgLpFVlo1Z-",
        "outputId": "277cc349-2ecc-4663-e2c5-5c5517e7571f"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN"
      },
      "source": [
        "–¢–∞–∫–∂–µ —Å–æ–∑–¥–∞–¥–∏–º –∏—Ç–µ—Ä–∞—Ç–æ—Ä —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞  DataLoader –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ torch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "# 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYQ3iLO08SX"
      },
      "source": [
        "–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –¥–∞–Ω–Ω—ã–µ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω—ã, –º–æ–∂–µ–º –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "## 4.1. BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sjzRT1V0zwm"
      },
      "source": [
        "–î–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Å–∏–µ–π –ø—Ä–µ–æ–±—É—á–µ–Ω–Ω–æ–≥–æ BERT'–∞ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–º —Å–ª–æ–µ–º –ø–æ–≤–µ—Ä—Ö –æ—Å–Ω–æ–≤–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\n",
        "\n",
        "–í –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ huggingface –¥–ª—è BERT —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Ü–µ–ª—ã–π —Ä—è–¥ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –º–Ω–æ–≥–∏—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á.\n",
        "\n",
        "–ö–ª–∞—Å—Å—ã –¥–ª—è fine-tuning:\n",
        "* BertModel\n",
        "* BertForPreTraining\n",
        "* BertForMaskedLM\n",
        "* BertForNextSentencePrediction\n",
        "* **BertForSequenceClassification** - The one we'll use.\n",
        "* BertForTokenClassification\n",
        "* BertForQuestionAnswering\n",
        "\n",
        "–ü–æ–ª–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –º–æ–∂–Ω–æ –ø–æ—á–∏—Ç–∞—Ç—å [–∑–¥–µ—Å—å](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYitPoE-cjH"
      },
      "source": [
        "\n",
        "\n",
        "–ú—ã –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). –≠—Ç–æ –æ–±—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å BERT —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –ª–∏–Ω–µ–π–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–ª–æ—è –ø–æ–≤–µ—Ä—Ö –æ—Å–Ω–æ–≤–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnQW9E-bBCRt"
      },
      "source": [
        "\n",
        "OK, –∑–∞–≥—Ä—É–∑–∏–º BERT! –ù–∞ —Å–∞–π—Ç–µ huggingface –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π BERT, –º—ã –≤—ã–±–µ—Ä–µ–º \"bert-base-uncased\".\n",
        "\n",
        "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –º–µ—Ç–æ–¥–∞ `from_pretrained` –º–æ–∂–Ω–æ –ø–æ—á–∏—Ç–∞—Ç—å [–∑–¥–µ—Å—å](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ [–∑–¥–µ—Å—å](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d6222c9cac434deb89d8efda832e39fd",
            "1e1de17d6c884f40bab8d8fdb1bce7c6",
            "58f45083fe0847a4bd6c7e6c684d9af0",
            "b05636d383ed4b1bb8000824113aff22",
            "b2b4bff4c7e74dbb87f0213a3688362b",
            "ed43a18dd0c74de2b97202e2bf60e149",
            "136e8a953ae84265bd9772beca57c734",
            "01393675009a43648fbbfe55e8ece7ec",
            "d7b4c46785e049b0a199e3d79afcd0e8",
            "f9493efa54614d3abfe260fa47c3f584",
            "ba677ae701f444f7bbfa44026091940c"
          ]
        },
        "id": "gFsCTp_mporB",
        "outputId": "45278bda-1221-440f-d9ab-38121465dda7"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6222c9cac434deb89d8efda832e39fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Jv6c7-HHDW"
      },
      "source": [
        "–†–∞–¥–∏ –∏–Ω—Ç–µ—Ä–µ—Å–∞ –≤—ã–≤–µ–¥–µ–º –Ω–∞ –ø–µ—á–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–æ–µ–≤:\n",
        "\n",
        "\n",
        "1. The embedding layer.\n",
        "2. –ü–µ—Ä–≤—ã–π –∏–∑ 12—Ç–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤.\n",
        "3. The output layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PIiVlDYCtSq",
        "outputId": "466e9e0c-39e1-448e-a057-bba161640a5b"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "–ü–æ—á—Ç–∏ –≤—Å–µ –≥–æ—Ç–æ–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –æ—Å—Ç–∞–ª–æ—Å—å –∑–∞–¥–∞—Ç—å optimizer –∏ sheduler, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –Ω–∞–º —Å —Ñ–∞–π–Ω—Ç—å—é–Ω–æ–º. \n",
        "\n",
        "–ù–∞–∏–±–æ–ª–µ–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:\n",
        ">- **Batch size:** 16, 32  \n",
        "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "- **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "–ú—ã –≤—ã–±–µ—Ä–µ–º:\n",
        "* Batch size: 32 (–∑–∞–¥–∞–µ—Ç—Å—è –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 4 \n",
        "\n",
        "–ü–∞—Ä–∞–º–µ—Ç—Ä —ç–ø—Å–∏–ª–æ–Ω `eps = 1e-8` - —ç—Ç–æ \"–æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–µ —á–∏—Å–ª–æ\", –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0 (–ø–æ–¥—Ä–æ–±–Ω–µ–µ –ø—Ä–æ –Ω–µ–≥–æ –º–æ–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å [–∑–¥–µ—Å—å](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "–ê –ø—Ä–∏–º–µ—Ä –¥–ª—è AdamW optimizer –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ `run_glue.py` [–∑–¥–µ—Å—å](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b98be6-2dc1-4d17-adba-93167ae39faf"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5"
      },
      "source": [
        "–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ –ø–µ—Ç–ª—è –æ–±—É—á–µ–Ω–∏—è (training loop). –ù–∞ –∫–∞–∂–¥–æ–º –ø—Ä–æ—Ö–æ–¥–µ –ø–æ –¥–∞–Ω–Ω—ã–º –º—ã –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º—É –æ–±—É—á–∞—é—â–µ–º—É –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –¥–∞—Ç–∞—Å–µ—Ç–∞–º. \n",
        "\n",
        "\n",
        "**Training:**\n",
        "- –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ –ª–µ–π–±–ª—ã\n",
        "- –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ GPU –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
        "- –ó–∞–Ω—É–ª–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —à–∞–≥–µ \n",
        "- Forward pass (—Å–∫–æ—Ä–º–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –∏ –ø—Ä–æ–±—Ä–æ—Å–∏—Ç—å –∏—Ö –≤–ø–µ—Ä–µ–¥)\n",
        "- Backward pass (backpropagation - –ø–æ—Å—á–∏—Ç–∞—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º —Å –ø–æ–º–æ—â—å—é –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏)\n",
        "- –û–±–Ω–æ–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å –ø–æ–º–æ—â—å—é optimizer.step()\n",
        "- –ü–æ—Å—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, —á—Ç–æ–±—ã —Å–ª–µ–¥–∏—Ç—å –∑–∞ –æ–±—É—á–µ–Ω–∏–µ–º\n",
        "\n",
        "**Evaluation:**\n",
        "- –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –ª–µ–π–±–ª—ã\n",
        "- –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ GPU –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
        "- Forward pass (—Å–∫–æ—Ä–º–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –∏ –ø—Ä–æ–±—Ä–æ—Å–∏—Ç—å –∏—Ö –≤–ø–µ—Ä–µ–¥)\n",
        "- –ü–æ—Å—á–∏—Ç–∞—Ç—å loss –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã —Å–ª–µ–¥–∏—Ç—å –∑–∞ –æ–±—É—á–µ–Ω–∏–µ–º\n",
        "\n",
        "Pytorch –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∑–∞ –Ω–∞—Å, –Ω–∞–º –æ—Å—Ç–∞–µ—Ç—Å—è —Å–¥–µ–ª–∞—Ç—å —Å–æ–≤—Å–µ–º –Ω–µ–º–Ω–æ–≥–æ. \n",
        "\n",
        "–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3"
      },
      "source": [
        "–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∑–∞—Ç—Ä–∞—á–µ–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N"
      },
      "source": [
        "–í—Å–µ –≥–æ—Ç–æ–≤–æ –∫ –æ–±—É—á–µ–Ω–∏—é! –ü—Ä–∏—Å—Ç—É–ø–∏–º!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J-FYdx6nFE_",
        "outputId": "b46af174-5e9b-4d3c-a98e-85caa89e9ab4"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        res = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = res['loss']\n",
        "        logits = res['logits']\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            res = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "        loss = res['loss']\n",
        "        logits = res['logits']\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:11.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:24.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.40\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:54.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:07.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:21.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:40.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:54.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:07.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:21.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.45\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:40.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:54.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:07.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:21.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.53\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:05:39 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–∞–º–º–∞—Ä–∏ –æ–±—É—á–∞—é—â–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6O_NbXFGMukX",
        "outputId": "5fb58e66-9dc7-43ef-b917-52a4f144de19"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.49         0.40           0.83       0:01:24         0:00:03\n",
              "2               0.30         0.39           0.84       0:01:21         0:00:03\n",
              "3               0.20         0.45           0.85       0:01:21         0:00:03\n",
              "4               0.14         0.53           0.85       0:01:21         0:00:03"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea44b399-d7a3-4bee-a4f2-1976b07762b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.49</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:01:21</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:01:21</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:01:21</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea44b399-d7a3-4bee-a4f2-1976b07762b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea44b399-d7a3-4bee-a4f2-1976b07762b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea44b399-d7a3-4bee-a4f2-1976b07762b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ loss –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ –ø–∞–¥–∞–µ—Ç, –∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç–∞—Ç—å. –≠—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –æ —Ç–æ–º, —á—Ç–æ –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è.\n",
        "\n",
        "Loss –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–±, —á–µ–º accuracy, —Ç–∞–∫ –∫–∞–∫ accuracy –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–∏–ø–∞ –æ—à–∏–±–∫–∏ –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –≤ –æ—Ç–≤–µ—Ç–µ. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "68xreA9JAmG5",
        "outputId": "227773e1-644f-4bd8-b86b-142f25ec37f6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# 5. Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DosV94BYIYxg"
      },
      "source": [
        "–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ. –î–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞—Ñ–∞–π–Ω—Ç—å—é–Ω–µ–Ω–æ–π –º–æ–¥–µ–ª–∏ –æ—Ü–µ–Ω–∏–º –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º [–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ú—ç—Ç—å—é—Å–∞](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html). –≠—Ç–∞ –º–µ—Ç—Ä–∏–∫–∞ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ —ç—Ç–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ú—ç—Ç—å—é—Å–∞ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è –æ—Ç -1 –¥–æ +1, —á–µ–º –æ–Ω–∞ –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### 5.1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "–ü—Ä–∏–º–µ–Ω–∏–º –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º —Ç–µ –∂–µ —à–∞–≥–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –ø—Ä–∏–º–µ–Ω—è–ª–∏ –¥–ª—è –æ–±—É—á–∞—é—â–µ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–∫."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "p_QuIaZnDa0g",
        "outputId": "b3ff5110-4d5d-428b-8ddf-8beee6fff4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  sentence_source  label label_notes  \\\n",
              "0           clc95      1         NaN   \n",
              "1           clc95      1         NaN   \n",
              "2           clc95      1         NaN   \n",
              "3           clc95      1         NaN   \n",
              "4           clc95      1         NaN   \n",
              "\n",
              "                                            sentence  \n",
              "0                    Somebody just left - guess who.  \n",
              "1  They claimed they had settled on something, bu...  \n",
              "2          If Sam was going, Sally would know where.  \n",
              "3  They're going to serve the guests something, b...  \n",
              "4               She's reading. I can't imagine what.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b856358-094e-43f1-b36b-0796f5bfff52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clc95</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Somebody just left - guess who.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clc95</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They claimed they had settled on something, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clc95</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>If Sam was going, Sally would know where.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clc95</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They're going to serve the guests something, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>clc95</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>She's reading. I can't imagine what.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b856358-094e-43f1-b36b-0796f5bfff52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b856358-094e-43f1-b36b-0796f5bfff52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b856358-094e-43f1-b36b-0796f5bfff52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAN0LZBOOPVh",
        "outputId": "da906964-7b01-4d0f-b21c-ee02ce93f96b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "## 5.2. –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–µ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "–ü–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –º—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hba10sXR7Xi6",
        "outputId": "4874f00a-b07d-4922-f84b-2d91791c4ded"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jscIM8R4Gv"
      },
      "source": [
        "–í –∫–∞—á–µ—Å—Ç–≤–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–æ–∑—å–º–µ–º [–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ú—ç—Ç—å—é—Å–∞](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) (Matthews correlation coefficient, —Å–æ–∫—Ä–∞—â–µ–Ω–Ω–æ MCC).\n",
        "\n",
        "–î–∞–Ω–Ω—É—é –º–µ—Ç—Ä–∏–∫—É –∏—Å–ø–æ–ª—å–∑—É—é—Ç –≤ —Å–∏–ª—É –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWcy0X1hirdx",
        "outputId": "db1e1cf2-aa77-4457-c518-8ad36dd09473"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRaZQ4XC7kLs",
        "outputId": "f10ac6c1-88c6-41a3-98f8-84650accd725"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUM0UA1qJaVB"
      },
      "source": [
        "–§–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø–æ –≤—Å–µ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É, –Ω–æ –¥–∞–≤–∞–π—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–∫–æ—Ä—ã –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –±–∞—Ç—á–∞—Ö. \n",
        "\n",
        "–ö–∞–∂–¥—ã–π –±–∞—Ç—á –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏—Ç 32 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è 32. –ü–æ—Å–ª–µ–¥–Ω–∏–π —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ(516 % 32) = 4 —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–∞.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "pyfY1tqxU0t9",
        "outputId": "4b4cc663-c6dd-49de-9763-5ad21ea23625"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YrjAPX2V-l4"
      },
      "source": [
        "–û–±—ä–µ–¥–∏–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ø–æ–ª—É—á–∏–º –æ–±—â–∏–π MCC —Å–∫–æ—Ä."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCYZa1lQ8Jn8",
        "outputId": "e867bcd9-bac8-420b-8480-78be37317126"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXx0jPc4HUfZ"
      },
      "source": [
        "**–ó–¥–æ—Ä–æ–≤–æ!** –í—Å–µ–≥–æ –ø–æ–ª—á–∞—Å–∞ —Ä–∞–±–æ—Ç—ã –∏ –±–µ–∑ –≤—Å—è–∫–æ–≥–æ —Ç—é–Ω–∏–Ω–≥–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–ø–æ–¥–±–æ—Ä–∞ learning rate, —á–∏—Å–ª–∞ —ç–ø–æ—Ö epochs, —Ä–∞–∑–º–µ—Ä–∞ batch size –∏ —Ç. –¥.) –º—ã –ø–æ–ª—É—á–∏–ª–∏ —Ç–∞–∫–æ–π —Ö–æ—Ä–æ—à–∏–π —Å–∫–æ—Ä! \n",
        "\n",
        "\n",
        "–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –ª–∏–¥–µ—Ä–±–æ—Ä–¥ –¥–ª—è —ç—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ [–∑–¥–µ—Å—å](https://gluebenchmark.com/leaderboard/submission/zlssuBTm5XRs0aSKbFYGVIVdvbj1/-LhijX9VVmvJcvzKymxy). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "# –ó–∞–∫–ª—é—á–µ–Ω–∏–µ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlQG7qgkmf4n"
      },
      "source": [
        "–ú—ã –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏ –ø—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é BERT –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ huggingface! –û–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è —Ñ–∞–π–Ω—Ç—å—é–Ω–∏—Ç—å –±–æ–ª—å—à–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∫–∏ –Ω–µ—Å–ª–æ–∂–Ω–æ, –Ω–æ –æ—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –∏ –ø–æ–ª–µ–∑–Ω–æ ;)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUmsUOIv8EUO"
      },
      "source": [
        "# Appendix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "##  Saving & Loading Fine-Tuned Model\n",
        "\n",
        "–ö–æ–¥ –Ω–∏–∂–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏ —Å–æ–æ—Ç–≤–µ—Å—Ç–≤—É—é—â–∏–π –µ–π —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –Ω–∞ –¥–∏—Å–∫. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ulTWaOr8QNY",
        "outputId": "fdc8dd9c-6c74-4c0b-f714-b241034466fb"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-tjHkR7lc1I"
      },
      "source": [
        "–ò–∑ –ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–∞ –ø—Ä–æ–≤–µ—Ä–∏–º —Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqMzI3VTCZo5",
        "outputId": "4950469a-9858-47fc-d9dc-308028c33418"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 427984K\n",
            "-rw-r--r-- 1 root root      1K Aug  1 22:26 config.json\n",
            "-rw-r--r-- 1 root root 427741K Aug  1 22:26 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Aug  1 22:26 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Aug  1 22:26 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    227K Aug  1 22:26 vocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr_bt2rFlgDn"
      },
      "source": [
        "–°–∞–º—ã–π –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª –≤–µ—Å–∏—Ç –æ–∫–æ–ª–æ 418 –º–µ–≥–∞–±–∞–π—Ç."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WUFUIQ8Cu8D",
        "outputId": "1359d0ac-0b4a-4835-bb59-bc99581ca2f7"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 418M Aug  1 22:26 ./model_save/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzGKvOFAll_e"
      },
      "source": [
        "–ö–æ–¥ –Ω–∏–∂–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑ –∫–æ–ª–∞–±–∞ –Ω–∞ Google Disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trr-A-POC18_"
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "#from google.colab import drive\n",
        "#    drive.mount('/content/drive')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5",
        "outputId": "38b2d106-15a7-4d27-abb9-d8ec40bb282f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ \"./drive/Shared drives/ChrisMcCormick.AI/Blog Posts/BERT Fine-Tuning/\""
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create directory './drive/Shared drives/ChrisMcCormick.AI/Blog Posts/BERT Fine-Tuning/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0vstijw85SZ"
      },
      "source": [
        "–ö–æ–¥ –Ω–∏–∂–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nskPzUM084zL",
        "outputId": "a247e19c-d597-43ee-fc85-3d2adbd373ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = model_class.from_pretrained(output_dir)\n",
        "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-decb3e924a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load a trained model and vocabulary that you have fine-tuned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Copy the model to the GPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_class' is not defined"
          ]
        }
      ]
    }
  ]
}